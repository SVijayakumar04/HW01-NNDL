{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3VDPBUuUPU88",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce99211581a52c7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exploring Cross-Validation\n",
    "\n",
    "This script will walk you through the process of fitting a linear model using polynomial basis functions, and the selection of a hyper-parameter using a validation data set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4DGqJ_O6oH4y",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-18a0ac62fbe6a202",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Data\n",
    "\n",
    "The data is generated using the following model: \n",
    "$$ y = f(x) + \\epsilon = 5x(x-0.5)(x-1) + \\epsilon$$\n",
    "where $\\epsilon \\sim N(0,0.01)$ is a Gaussian noise term with zero mean and standard deviation equal to 0.1.\n",
    "\n",
    "The training and test data have already been generated for you and the section below shows you how to load them and what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 179,
     "status": "ok",
     "timestamp": 1643396208953,
     "user": {
      "displayName": "Hangjin Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03706230453391698032"
     },
     "user_tz": 300
    },
    "id": "0UhvvvCiktSC",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2021e7a3401141ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "db804a15-9354-4860-af2e-7f0449f81865"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading training and test data\n",
    "x_train = np.loadtxt('Data/x_train.csv',delimiter=',')\n",
    "y_train = np.loadtxt('Data/y_train.csv',delimiter=',')\n",
    "x_test = np.loadtxt('Data/x_test.csv',delimiter=',')\n",
    "y_test = np.loadtxt('Data/y_test.csv',delimiter=',')\n",
    "\n",
    "# Plotting data purely for verification\n",
    "plt.plot(x_train,y_train,'k.',x_test,y_test,'r.')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend({'Training','Testing'})\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xUgAMT0kpoCj",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66d51021f24cebe8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Fitting a Polynomial to the Data\n",
    "\n",
    "The section below shows how to do a simple fit for a quadratic polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polyfit as pf\n",
    "\n",
    "# Fitting model\n",
    "deg = 2\n",
    "beta = pf.fit(x_train,y_train,deg)\n",
    "\n",
    "# Computing training error\n",
    "y_train_pred = pf.predict(x_train,beta)\n",
    "err = pf.rmse(y_train,y_train_pred)\n",
    "print('Training Error = {:2.3}'.format(err))\n",
    "\n",
    "# Computing test error\n",
    "y_test_pred = pf.predict(x_test,beta)\n",
    "err = pf.rmse(y_test,y_test_pred)\n",
    "print('Test Error = {:2.3}'.format(err))\n",
    "\n",
    "# Plotting fitted model\n",
    "x = np.linspace(0,1,100)\n",
    "y = pf.predict(x,beta)\n",
    "plt.plot(x,y,'b-',x_train,y_train,'ks',x_test,y_test,'rs')\n",
    "plt.legend(['Prediction','Training Points','Test Points'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "yeHh6aZqj1df",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-31600590538de41e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Hyper-Parameter Selection\n",
    "\n",
    "This section illustrates how to perform hyper-parameter selection where the capacity of the model is captured by the degree of the polynomial used for fitting.\n",
    "\n",
    "First, we fit the data to the entire training set and compute the corresponding training and test errors. We used all of the data since we are not performing any hyper-parameter selection at this point."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "82nBiLPT8qGB",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-25f6b8f6629f8828",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 1 [2 pts]\n",
    "\n",
    "Your first tasks is to split the data into pre-val training and validation for a K-fold cross validation. You should complete the function within the provided script. Keep all measurements in the same order as the original training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUe94pxk8mDS",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d7ebdb8d58c17e44",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import kfold_split as ks\n",
    "import importlib\n",
    "importlib.reload(ks)\n",
    "\n",
    "# This is the total number of folds\n",
    "K = 10\n",
    "\n",
    "# This is the function that needs to be modified within the specified block in the script.\n",
    "# Note that the last entry is the current k-fold splid to be returned. That is, passing a\n",
    "# value of 0 will return the first fold split with the first fold as the validation set.\n",
    "x_preval, y_preval, x_val, y_val = ks.kfold_split(x_train,y_train,K,0)\n",
    "\n",
    "print('Dimensions of Validation Set: {}'.format(x_val.shape))\n",
    "print('Dimensions of Pre-Validation Set: {}'.format(x_preval.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rngJuESIReF0",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-31098537f7c3ec3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2 [4 pts]\n",
    "\n",
    "Compute pre-validation training and validation errors for each of the listed degrees. The training error should show a decreasing pattern. The validation error should decrease and then increase. You should complete the function within the provided script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 362,
     "status": "ok",
     "timestamp": 1643397082961,
     "user": {
      "displayName": "Hangjin Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03706230453391698032"
     },
     "user_tz": 300
    },
    "id": "Na54JALAj1dq",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e72d51a7266e6f2d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "50685a69-f7e1-42ca-a468-b68ce36e8f14"
   },
   "outputs": [],
   "source": [
    "import kfold_crossval as kc\n",
    "importlib.reload(kc)\n",
    "\n",
    "# List of degrees considered for the analysis\n",
    "degList =  np.array([0,1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "# This is the total number of folds\n",
    "K = 10\n",
    "\n",
    "# Getting arrays with the errors for all folds. We keep track of all errors so\n",
    "# the mean and standard deviation can be computed below.\n",
    "errPreVal, errVal = kc.kfold_crossval(x_train,y_train,degList,K)\n",
    "\n",
    "# Computing means and standard deviation for the errors\n",
    "errPreVal_mean = np.mean(errPreVal,axis=1)\n",
    "errVal_mean = np.mean(errVal,axis=1)\n",
    "errVal_std = np.std(errVal,axis=1)\n",
    "\n",
    "# Plotting results\n",
    "plt.plot(degList,errPreVal_mean,'b.-',degList,errVal_mean,'r.-',degList,errVal_mean+errVal_std,'r--')\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend(['Mean Pre-Val Training Error','Mean Val Error','Mean Val Error + Std'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2O1CJfK7j1dv",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9447128e16c2b7ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Performance of Optimal Model\n",
    "\n",
    "We begin by selecting the optimal degree using this rule: *Select the most parsimonious model that has a cross-validation value within a standard deviation from the best model $\\theta^*$.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the index of the degree with minimum mean validation error\n",
    "idx = np.argmin(errVal_mean)\n",
    "\n",
    "# Getting list of degrees that are below the mininum error plus the std\n",
    "tmp = degList[errVal_mean<errVal_mean[idx]+errVal_std[idx]]\n",
    "\n",
    "# The optimal degree is the minimum of the previous list\n",
    "degOpt = min(tmp)\n",
    "\n",
    "print('Optimal Degree = {}'.format(degOpt))\n",
    "print('Mean Validation Error = {:.3f} +/- {:.3f}'.format(errVal_mean[idx],errVal_std[idx]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "u2OsE1bn_XuO",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05ed348ceb48a417",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, we fit a model with all the training data and show its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "beta = pf.fit(x_train,y_train,degOpt)\n",
    "y_test_pred = pf.predict(x_test,beta)\n",
    "errTest = pf.rmse(y_test,y_test_pred)\n",
    "\n",
    "# Displaying the test error\n",
    "print('Test Error = {:.3f}'.format(errTest))\n",
    "\n",
    "# Plotting fitted model\n",
    "x = np.linspace(0,1,100)\n",
    "y = pf.predict(x,beta) # Use the beta from the full training set for better visualization\n",
    "plt.plot(x,y,'b-',x_train,y_train,'ks',x_test,y_test,'rs')\n",
    "plt.legend(['Prediction','Training Points','Test Points'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "colab": {
   "collapsed_sections": [],
   "name": "hw02-SOL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nndl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
